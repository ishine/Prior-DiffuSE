train:
  batch_size: 10
  n_epochs: 50
  loss: "com_mag_mse_loss"
  chunk_length: 48000
  win_size: 320
  fft_num: 320
  win_shift: 160
  feat_type: "sqrt"  # normal sqrt cubic log_1x, or something else not in recommended list (maybe 'none')
  pesq_loss: False

model:
  name: 'DiffUNet'
model_ddpm:
  name: 'DiffWave'
optim:
  optimizer: 'Adam'
  lr: 0.001
  l2: 0.0000001
  half_lr: 3  # whether to decay learning rate to half scale.
  early_stop: 5   # early stop training when no improvement in k epochs.
